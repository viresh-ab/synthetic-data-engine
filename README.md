# ðŸ§¬ Hybrid Synthetic Data Platform

A production-ready synthetic data generator that combines:

- **SDV** â†’ Numeric & categorical realism
- **GPT LLMs** â†’ Natural language & survey responses
- **RAG** â†’ Business & domain constraints
- **Faker** â†’ Privacy-safe identity generation

---

## ðŸš€ Features

- Semantic column understanding
- Privacy-safe PII handling
- Non-repetitive text generation
- Business-rule-aware numeric synthesis
- Streamlit UI for easy usage

---

## ðŸ— Architecture Overview

| Data Type | Engine Used |
|---------|------------|
Numeric & categorical | SDV + RAG |
Names / Emails / IDs | Faker |
Text / Q&A / Opinions | GPT LLM |
Validation | Rule + Quality Metrics |

---

## ðŸ— File Structure

synthetic-data-platform/
â”‚
â”œâ”€â”€ app.py                    # Streamlit / API entry point
â”œâ”€â”€ config.yaml               # Global configuration
â”œâ”€â”€ requirements.txt          # Dependencies
â”œâ”€â”€ README.md                 # Project documentation
â”‚
â”œâ”€â”€ schema/                   # Step 1: Schema understanding
â”‚   â”œâ”€â”€ schema_profiler.py    # Semantic column classification
â”‚   â”œâ”€â”€ column_types.py       # Semantic type definitions
â”‚   â””â”€â”€ pii_detector.py       # PII identification logic
â”‚
â”œâ”€â”€ engines/                  # Core generation engines
â”‚   â”œâ”€â”€ sdv_engine.py         # SDV-based numeric synthesis
â”‚   â”œâ”€â”€ llm_engine.py         # GPT LLM text generation
â”‚   â”œâ”€â”€ rag_engine.py         # RAG constraint retrieval
â”‚   â”œâ”€â”€ faker_engine.py       # PII & identity generation
â”‚   â””â”€â”€ rule_engine.py        # Business rule enforcement
â”‚
â”œâ”€â”€ pipelines/                # Orchestration layers
â”‚   â”œâ”€â”€ numeric_pipeline.py   # SDV + RAG numeric pipeline
â”‚   â”œâ”€â”€ text_pipeline.py      # GPT text & persona pipeline
â”‚   â”œâ”€â”€ pii_pipeline.py       # Faker-based PII pipeline
â”‚   â””â”€â”€ hybrid_pipeline.py    # Final merge pipeline
â”‚
â”œâ”€â”€ prompts/                  # LLM prompt assets
â”‚   â”œâ”€â”€ base_prompt.txt       # Global LLM rules
â”‚   â”œâ”€â”€ fashion_personas.json # Persona definitions
â”‚   â””â”€â”€ column_prompts.yaml   # Column-specific instructions
â”‚
â”œâ”€â”€ validation/               # Quality & safety checks
â”‚   â”œâ”€â”€ schema_validator.py   # Schema alignment
â”‚   â”œâ”€â”€ rule_validator.py     # Business rule validation
â”‚   â””â”€â”€ quality_metrics.py    # Similarity & diversity metrics
â”‚
â””â”€â”€ .streamlit/
    â””â”€â”€ config.toml           # UI theme & layout

---

flowchart TD
    A[Real Input CSV] --> B[Schema Profiler<br/>Semantic Typing]

    B --> C1[Numeric Pipeline<br/>SDV + RAG]
    B --> C2[Text Pipeline<br/>GPT LLM + Personas]
    B --> C3[PII Pipeline<br/>Faker]

    C1 --> D[Hybrid Merger]
    C2 --> D
    C3 --> D

    D --> E[Validation Layer<br/>Schema + Rules]
    E --> F[Quality Metrics<br/>Similarity & Diversity]

    F --> G[Final Synthetic Dataset<br/>CSV Output]




## â–¶ How to Run

```bash
pip install -r requirements.txt
streamlit run app.py
